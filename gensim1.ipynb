{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "Build a corpus for gensim from individual text files.\n",
    "\"\"\"\n",
    "\n",
    "# == imports ==\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from os.path import join\n",
    "import re\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# == general parameters == \n",
    "\n",
    "workingdir = join(\"/\", \"media\", \"christof\", \"mydata\", \"Dropbox-alt\", \"0-Analysen\", \"2018\", \"poesia\", \"\")\n",
    "corpusfiles = [\n",
    "#join(workingdir, \"data\", \"raw\", \"17sonetos.txt\"),\n",
    "join(workingdir, \"data\", \"sel\", \"17sonetos.txt\"),\n",
    "join(workingdir, \"data\", \"sel\", \"17poesias.txt\"),\n",
    "join(workingdir, \"data\", \"sel\", \"18poesias.txt\"),\n",
    "join(workingdir, \"data\", \"sel\", \"19disco.txt\"),\n",
    "join(workingdir, \"data\", \"sel\", \"19poesias.txt\"),\n",
    "join(workingdir, \"data\", \"sel\", \"20poesias.txt\"),\n",
    "join(workingdir, \"data\", \"sel\", \"21poesias.txt\"),\n",
    "]\n",
    "\n",
    "stoplistfile = join(workingdir, \"gensim\", \"stoplist-es_lemmas.txt\")\n",
    "\n",
    "# == model parameters == \n",
    "\n",
    "numtopics = 40\n",
    "\n",
    "\n",
    "# == logging and resultsfolder == \n",
    "\n",
    "timestamp,ms = datetime.datetime.now().isoformat().split(\".\")\n",
    "resultsfolder = join(workingdir, \"gensim\", str(timestamp)+\"_17sonetos\", \"\")\n",
    "if not os.path.exists(resultsfolder): \n",
    "    os.makedirs(resultsfolder)\n",
    "\n",
    "logging.basicConfig(\n",
    "   filename = join(resultsfolder, \"modeling.log\"), \n",
    "   format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "   level=logging.INFO)\n",
    "\n",
    "\n",
    "# == functions == \n",
    "\n",
    "def read_corpusfiles(corpusfiles, stoplistfile): \n",
    "    with open(stoplistfile, \"r\", encoding=\"utf8\") as infile: \n",
    "        stoplist = infile.read().splitlines()\n",
    "    listcorpus = []\n",
    "    for corpusfile in corpusfiles: \n",
    "        with open(corpusfile, \"r\", encoding=\"utf8\") as infile: \n",
    "            corpus = infile.read().splitlines()\n",
    "            #onelistcorpus = [[token for token in re.split(\"\\W+\", text) if len(token) > 3] for text in corpus]\n",
    "            onelistcorpus = [[token for token in re.split(\"\\W+\", text) if token not in stoplist] for text in corpus]\n",
    "            listcorpus.extend(onelistcorpus)\n",
    "    listcorpus = [[token for token in line if token] for line in listcorpus]\n",
    "    #print(listcorpus)\n",
    "    return listcorpus\n",
    "\n",
    "\n",
    "def copy_stoplistfile(stoplistfile, resultsfolder): \n",
    "    basename = os.path.basename(stoplistfile)\n",
    "    copyfile(stoplistfile, join(resultsfolder, join(resultsfolder, basename)))\n",
    "\n",
    "\n",
    "def build_vectorcorpus(listcorpus, resultsfolder): \n",
    "    dictcorpus = corpora.Dictionary(listcorpus)\n",
    "    dictcorpus.save(join(resultsfolder, \"corpus.dict\"))\n",
    "    vectorcorpus = [dictcorpus.doc2bow(text) for text in listcorpus]\n",
    "    print(\"number of types\", len(dictcorpus))\n",
    "    #print(dictcorpus)\n",
    "    #print(dictcorpus.token2id)\n",
    "    #print(vectorcorpus)\n",
    "    return dictcorpus, vectorcorpus\n",
    "\n",
    "\n",
    "def build_model_multicore(dictcorpus, vectorcorpus, numtopics, workingdir, timestamp): \n",
    "    model = models.ldamulticore.LdaMulticore(\n",
    "        corpus=vectorcorpus,\n",
    "        id2word=dictcorpus,\n",
    "        num_topics=numtopics, \n",
    "        #random_state=100,\n",
    "        #update_every=1000,\n",
    "        #chunksize=100,\n",
    "        passes=500,\n",
    "        workers=3,\n",
    "        per_word_topics=True)\n",
    "    model.save(join(resultsfolder, \"model.gensim\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_singlecore(dictcorpus, vectorcorpus, numtopics, workingdir, timestamp): \n",
    "    model = models.ldamodel.LdaModel(\n",
    "        corpus=vectorcorpus,\n",
    "        id2word=dictcorpus,\n",
    "        num_topics=numtopics, \n",
    "        #random_state=100,\n",
    "        update_every=1000,\n",
    "        chunksize=1000,\n",
    "        passes=500,\n",
    "        alpha='auto',\n",
    "        per_word_topics=True)\n",
    "    model.save(join(resultsfolder, \"model.gensim\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_topics(model, numtopics, resultsfolder): \n",
    "    topics = []\n",
    "    for i in range(0,numtopics): \n",
    "        topic = model.show_topic(i, topn=500)\n",
    "        topic = list(zip(*topic))\n",
    "        topic = pd.Series(topic[1], index=topic[0], name=str(i))\n",
    "        topics.append(topic)\n",
    "    topics = pd.concat(topics, axis=1, keys=[topic.name for topic in topics], sort=False)\n",
    "    topics = topics.fillna(0)\n",
    "    with open(join(resultsfolder, \"topics.csv\"), \"w\", encoding=\"utf8\") as outfile: \n",
    "        topics.to_csv(outfile, sep=\"\\t\")\n",
    "    \n",
    "\n",
    "\n",
    "def visualize_model(model, dictcorpus, vectorcorpus, resultsfolder):\n",
    "    visualization = pyLDAvis.gensim.prepare(\n",
    "        model, \n",
    "        vectorcorpus, \n",
    "        dictcorpus, \n",
    "        sort_topics=False)\n",
    "    pyLDAvis.save_html(visualization, join(resultsfolder, \"visualization.html\"))\n",
    "\n",
    "\n",
    "def check_coherence(listcorpus, vectorcorpus, model, numtopics, resultsfolder): \n",
    "    # coherence for the entire model, using several measures\n",
    "    measures = [\"c_v\", \"c_npmi\", \"u_mass\", \"c_uci\"]\n",
    "    coherences = []\n",
    "    for measure in measures: \n",
    "        coherencemodel = CoherenceModel(texts=listcorpus, model=model, corpus=vectorcorpus, coherence=measure, processes=3)\n",
    "        coherence = coherencemodel.get_coherence()\n",
    "        coherences.append(coherence)\n",
    "    coherences = dict(zip(measures, coherences))\n",
    "    coherences = pd.DataFrame.from_dict(coherences, orient='index', columns=[\"score\"])\n",
    "    with open(join(resultsfolder, \"coherences-model.csv\"), \"w\", encoding=\"utf8\") as outfile: \n",
    "        coherences.to_csv(outfile, sep=\"\\t\")\n",
    "    # coherence of each topic, using one measure only\n",
    "    coherencemodel = CoherenceModel(texts=listcorpus, model=model, corpus=vectorcorpus, coherence=\"c_v\", processes=3)    \n",
    "    coherences = list(zip(range(0,numtopics), coherencemodel.get_coherence_per_topic()))\n",
    "    coherences = pd.DataFrame(coherences, columns=[\"topic\", \"score\"]).sort_values(by=\"score\", ascending=False)\n",
    "    with open(join(resultsfolder, \"coherences-topics.csv\"), \"w\", encoding=\"utf8\") as outfile: \n",
    "        coherences.to_csv(outfile, sep=\"\\t\")\n",
    "\n",
    "\n",
    "# == main == \n",
    "\n",
    "def main(workingdir, corpusfiles, stoplistfile, resultsfolder, numtopics):\n",
    "    copy_stoplistfile(stoplistfile, resultsfolder)\n",
    "    listcorpus = read_corpusfiles(corpusfiles, stoplistfile)\n",
    "    dictcorpus, vectorcorpus = build_vectorcorpus(listcorpus, resultsfolder)\n",
    "    #model = build_model_multicore(dictcorpus, vectorcorpus, numtopics, workingdir, resultsfolder)\n",
    "    model = build_model_singlecore(dictcorpus, vectorcorpus, numtopics, workingdir, resultsfolder)\n",
    "    #model = models.ldamodel.LdaModel.load(join(workingdir, \"gensim\", \"2018-08-22T15:33:09_poesia-17\", \"model.gensim\"))\n",
    "    topics = get_topics(model, numtopics, resultsfolder)\n",
    "    visualize_model(model, dictcorpus, vectorcorpus, resultsfolder)\n",
    "    check_coherence(listcorpus, vectorcorpus, model, numtopics, resultsfolder)\n",
    "      \n",
    "main(workingdir, corpusfiles, stoplistfile, resultsfolder, numtopics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
